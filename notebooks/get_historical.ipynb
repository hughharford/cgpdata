{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DATA FROM ALPHA VANTAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY2 = os.getenv(\"HSTH_AV_KEY\")\n",
    "\n",
    "\n",
    "SOURCE=\"alphavantage\"\n",
    "API_KEY = KEY2\n",
    "YYYY=\"2000\"\n",
    "MM=\"01\"\n",
    "INTERVAL=\"5min\"\n",
    "TICKER=\"SPY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historicals_from_alphavantage():\n",
    "    print(\"getting data\")\n",
    "\n",
    "    # url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=SPY&interval=5min&apikey={API_KEY}\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={TICKER}&interval={INTERVAL}&month={YYYY}-{MM}&outputsize=full&apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking to get data\n"
     ]
    }
   ],
   "source": [
    "data = get_historicals_from_alphavantage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     1. open  2. high   3. low 4. close 5. volume\n",
      "2000-01-31 16:30:00  88.8758  88.8758  88.8758  88.8758       100\n",
      "2000-01-31 16:20:00  88.9156  88.9156  88.9156  88.9156      2000\n",
      "2000-01-31 16:15:00  88.8758  88.8758  88.8758  88.8758     20500\n",
      "2000-01-31 16:10:00  88.8957  88.9355  88.7763  88.8758     77600\n",
      "2000-01-31 16:05:00  88.7763  88.8559  88.7564  88.8360     99300\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data[\"Time Series (5min)\"], orient=\"index\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = f\"{YYYY}-{MM}-{TICKER}_{INTERVAL}_{SOURCE}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(f\"../data/{csv_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPLOAD DATA TO GOOGLE CLOUD BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket:        bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload:  source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object:        destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to upload is aborted if the object's\n",
    "    # generation number does not match your precondition. For a destination\n",
    "    # object that does not yet exist, set the if_generation_match precondition to 0.\n",
    "    # If the destination object already exists in your bucket, set instead a\n",
    "    # generation-match precondition using its generation number.\n",
    "    generation_match_precondition = 0\n",
    "\n",
    "    blob.upload_from_filename(source_file_name, if_generation_match=generation_match_precondition)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"cgpdata\"\n",
    "source_file_name = f\"../data/{csv_name}\"\n",
    "destination_blob_name = f\"raw/{csv_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../data/2000-01-SPY_5min_alphavantage.csv uploaded to raw/2000-01-SPY_5min_alphavantage.csv.\n"
     ]
    }
   ],
   "source": [
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
