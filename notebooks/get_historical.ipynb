{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DATA FROM ALPHA VANTAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY2 = os.getenv(\"HSTH_AV_KEY\")\n",
    "\n",
    "\n",
    "SOURCE=\"alphavantage\"\n",
    "API_KEY = KEY2\n",
    "YYYY=\"2023\"\n",
    "MM=\"12\"\n",
    "INTERVAL=\"5min\"\n",
    "TICKER=\"SPY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historicals_from_alphavantage():\n",
    "    print(\"getting data\")\n",
    "\n",
    "    # url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=SPY&interval=5min&apikey={API_KEY}\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={TICKER}&interval={INTERVAL}&month={YYYY}-{MM}&outputsize=full&apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data\n"
     ]
    }
   ],
   "source": [
    "data = get_historicals_from_alphavantage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-SPY_5min_alphavantage.csv  2023-3-SPY_5min_alphavantage.csv\n",
      "2022-11-SPY_5min_alphavantage.csv  2023-4-SPY_5min_alphavantage.csv\n",
      "2022-12-SPY_5min_alphavantage.csv  2023-5-SPY_5min_alphavantage.csv\n",
      "2023-10-SPY_5min_alphavantage.csv  2023-6-SPY_5min_alphavantage.csv\n",
      "2023-11-SPY_5min_alphavantage.csv  2023-7-SPY_5min_alphavantage.csv\n",
      "2023-12-SPY_5min_alphavantage.csv  2023-8-SPY_5min_alphavantage.csv\n",
      "2023-1-SPY_5min_alphavantage.csv   2023-9-SPY_5min_alphavantage.csv\n",
      "2023-2-SPY_5min_alphavantage.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-10 20:00:00</td>\n",
       "      <td>560.580</td>\n",
       "      <td>560.58</td>\n",
       "      <td>560.5800</td>\n",
       "      <td>560.5800</td>\n",
       "      <td>3586303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-10 19:55:00</td>\n",
       "      <td>558.600</td>\n",
       "      <td>558.71</td>\n",
       "      <td>558.3800</td>\n",
       "      <td>558.5118</td>\n",
       "      <td>21280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-10 19:50:00</td>\n",
       "      <td>558.770</td>\n",
       "      <td>558.85</td>\n",
       "      <td>558.5400</td>\n",
       "      <td>558.6500</td>\n",
       "      <td>17102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-10 19:45:00</td>\n",
       "      <td>558.275</td>\n",
       "      <td>558.88</td>\n",
       "      <td>558.2025</td>\n",
       "      <td>558.8175</td>\n",
       "      <td>25557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-10 19:40:00</td>\n",
       "      <td>557.960</td>\n",
       "      <td>558.41</td>\n",
       "      <td>557.7700</td>\n",
       "      <td>558.2750</td>\n",
       "      <td>31580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>2025-02-10 04:20:00</td>\n",
       "      <td>603.060</td>\n",
       "      <td>603.14</td>\n",
       "      <td>603.0000</td>\n",
       "      <td>603.0300</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>2025-02-10 04:15:00</td>\n",
       "      <td>602.990</td>\n",
       "      <td>603.15</td>\n",
       "      <td>602.9600</td>\n",
       "      <td>603.0200</td>\n",
       "      <td>2131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>2025-02-10 04:10:00</td>\n",
       "      <td>602.810</td>\n",
       "      <td>603.00</td>\n",
       "      <td>602.7600</td>\n",
       "      <td>603.0000</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>2025-02-10 04:05:00</td>\n",
       "      <td>602.850</td>\n",
       "      <td>602.94</td>\n",
       "      <td>602.6900</td>\n",
       "      <td>602.8700</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>2025-02-10 04:00:00</td>\n",
       "      <td>603.850</td>\n",
       "      <td>603.85</td>\n",
       "      <td>602.1600</td>\n",
       "      <td>602.8200</td>\n",
       "      <td>6064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3860 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0  1. open  2. high    3. low  4. close  5. volume\n",
       "0     2025-03-10 20:00:00  560.580   560.58  560.5800  560.5800    3586303\n",
       "1     2025-03-10 19:55:00  558.600   558.71  558.3800  558.5118      21280\n",
       "2     2025-03-10 19:50:00  558.770   558.85  558.5400  558.6500      17102\n",
       "3     2025-03-10 19:45:00  558.275   558.88  558.2025  558.8175      25557\n",
       "4     2025-03-10 19:40:00  557.960   558.41  557.7700  558.2750      31580\n",
       "...                   ...      ...      ...       ...       ...        ...\n",
       "3855  2025-02-10 04:20:00  603.060   603.14  603.0000  603.0300       1712\n",
       "3856  2025-02-10 04:15:00  602.990   603.15  602.9600  603.0200       2131\n",
       "3857  2025-02-10 04:10:00  602.810   603.00  602.7600  603.0000        856\n",
       "3858  2025-02-10 04:05:00  602.850   602.94  602.6900  602.8700       2352\n",
       "3859  2025-02-10 04:00:00  603.850   603.85  602.1600  602.8200       6064\n",
       "\n",
       "[3860 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"2022-8-SPY_5min_alphavantage.csv\"\n",
    "filename_n_path = f\"../data/{filename}\"\n",
    "data = pd.read_csv(filename_n_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0  1. open  2. high    3. low  4. close  5. volume\n",
      "0  2025-03-10 20:00:00  560.580   560.58  560.5800  560.5800    3586303\n",
      "1  2025-03-10 19:55:00  558.600   558.71  558.3800  558.5118      21280\n",
      "2  2025-03-10 19:50:00  558.770   558.85  558.5400  558.6500      17102\n",
      "3  2025-03-10 19:45:00  558.275   558.88  558.2025  558.8175      25557\n",
      "4  2025-03-10 19:40:00  557.960   558.41  557.7700  558.2750      31580\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename_n_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-03-10'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Unnamed: 0\"][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-03-10'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "(datetime.today()- timedelta(1)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Time Series (5min)'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hughharford/cgpdata/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3791\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3790\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3792\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:152\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:181\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Time Series (5min)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = pd.DataFrame.from_dict(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTime Series (5min)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, orient=\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hughharford/cgpdata/.venv/lib/python3.12/site-packages/pandas/core/frame.py:3893\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   3892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m3893\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   3895\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hughharford/cgpdata/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3798\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3793\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3794\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3795\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3796\u001b[39m     ):\n\u001b[32m   3797\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3798\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3799\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3800\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3801\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3803\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Time Series (5min)'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data[\"Time Series (5min)\"], orient=\"index\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = f\"{YYYY}-{MM}-{TICKER}_{INTERVAL}_{SOURCE}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(f\"../data/{csv_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPLOAD DATA TO GOOGLE CLOUD BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket:        bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload:  source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object:        destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to upload is aborted if the object's\n",
    "    # generation number does not match your precondition. For a destination\n",
    "    # object that does not yet exist, set the if_generation_match precondition to 0.\n",
    "    # If the destination object already exists in your bucket, set instead a\n",
    "    # generation-match precondition using its generation number.\n",
    "    generation_match_precondition = 0\n",
    "\n",
    "    blob.upload_from_filename(source_file_name, if_generation_match=generation_match_precondition)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"cgpdata\"\n",
    "source_file_name = f\"../data/{csv_name}\"\n",
    "gcpbucket_folder_string = \"hist\"\n",
    "destination_blob_name = f\"{gcpbucket_folder_string}/{csv_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../data/2023-12-SPY_5min_alphavantage.csv uploaded to hist/2023-12-SPY_5min_alphavantage.csv.\n"
     ]
    }
   ],
   "source": [
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
